{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679cf1a6-6052-4573-a306-239d251687ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# British Airwaysの顧客レビュー内容を日本語翻訳\n",
    "- サーバレスコンピュートを使用します\n",
    "- Kaggle [Airline Review](https://www.kaggle.com/datasets/chaudharyanshul/airline-reviews)のデータセットを使用します\n",
    "\n",
    "Note:  \n",
    "Anshul Chaudhary, & Muskan Risinghani. (2023). Airline Reviews [Data set]. Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7811aa7-4801-4d86-a966-cb9f9d07206a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 想定のディレクトリ構成\n",
    "```\n",
    "/<catalog_name>\n",
    "├── airline_reviews                           <- スキーマ\n",
    "│   ├── bz_reviews_en                         <- テーブル：bzonze/レビュー英語\n",
    "│   ├── bz_reviews_ja                         <- テーブル：bzonze/レビュー日本語\n",
    "│   ├── sv_reviews_summaries                  <- テーブル：silver/レビュー要約サマリ\n",
    "│   ├── sv_reviews_vectors                    <- テーブル：silver/レビュー要約サマリベクトル\n",
    "│   ├── sv_reviews_clusters                   <- テーブル：silver/レビューカテゴリ（クラスタ別）\n",
    "│   ├── raw_data                              <- ボリューム\n",
    "│       ├── EN/BA_AirlineReviews.csv             <- KaggleからダウンロードしたCSVを手動アップロード\n",
    "│       ├── JA/BA_AirlineReviews.csv             <- 日本語翻訳CSV\n",
    "```\n",
    "\n",
    "#### 処理概要\n",
    "1. レビュー内容を日本語翻訳 -> CSV出力\n",
    "1. レビュー内容をLLMでサマライズ -> サマリーをベクトルに変換\n",
    "1. ベクトルをNクラスターに分類 -> カテゴリごとにサマライズしてカテゴリ名を作成 -> ベクトルを2次元でプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67482310-8659-4baa-9172-73f0490c68c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa2f9e94-eeb2-40c4-8f21-39709af140ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. csvロード＆bronzeテーブル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66227242-ff11-4060-9581-ad12a23ee92f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "\n",
    "# スキーマの定義\n",
    "schema = StructType([\n",
    "    StructField(\"No\", IntegerType(), True),\n",
    "    StructField(\"OverallRating\", StringType(), True),\n",
    "    StructField(\"ReviewHeader\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Datetime\", StringType(), True),\n",
    "    StructField(\"VerifiedReview\", StringType(), True),\n",
    "    StructField(\"ReviewBody\", StringType(), True),\n",
    "    StructField(\"TypeOfTraveller\", StringType(), True),\n",
    "    StructField(\"SeatType\", StringType(), True),\n",
    "    StructField(\"Route\", StringType(), True),\n",
    "    StructField(\"DateFlown\", StringType(), True),\n",
    "    StructField(\"SeatComfort\", StringType(), True),\n",
    "    StructField(\"CabinStaffService\", StringType(), True),\n",
    "    StructField(\"GroundService\", StringType(), True),\n",
    "    StructField(\"ValueForMoney\", StringType(), True),\n",
    "    StructField(\"Recommended\", StringType(), True),\n",
    "    StructField(\"Aircraft\", StringType(), True),\n",
    "    StructField(\"FoodandBeverages\", StringType(), True),\n",
    "    StructField(\"InflightEntertainment\", StringType(), True),\n",
    "    StructField(\"WifiandConnectivity\", StringType(), True)\n",
    "])\n",
    "\n",
    "# read files\n",
    "df = spark.read.format(\"csv\") \\\n",
    "                .option(\"multiLine\", True) \\\n",
    "                .option(\"quote\", '\"') \\\n",
    "                .option(\"escape\", '\"') \\\n",
    "                .option(\"header\", True) \\\n",
    "                .schema(schema) \\\n",
    "                .load(f\"/Volumes/{MY_CATALOG}/{MY_SCHEMA}/{MY_VOLUME}/EN/\")\n",
    "\n",
    "# write table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{MY_CATALOG}.{MY_SCHEMA}.bz_reviews_en\")\n",
    "\n",
    "print(df.count())\n",
    "print(df.columns)\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d7dcc2-618f-4b91-90b0-594eebb74704",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TypeOfTraveller"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select TypeOfTraveller, count(*) as cnt\n",
    "# from bz_reviews_en\n",
    "# group by 1\n",
    "# order by 2 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "caf9a410-5068-435b-bc35-c088e27fd32d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SeatType"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select SeatType, count(*) as cnt\n",
    "# from bz_reviews_en\n",
    "# group by 1\n",
    "# order by 2 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1c0e685d-06a7-429f-9a88-b0afa6c1ab2b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Route"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select Route, count(*) as cnt\n",
    "# from bz_reviews_en\n",
    "# group by 1\n",
    "# order by 2 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "946a7fb3-4687-497d-ac72-f7ce1d492a49",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Aircraft"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select Aircraft, count(*) as cnt\n",
    "# from bz_reviews_en\n",
    "# group by 1\n",
    "# order by 2 desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baf8bd2d-ba6e-426e-a29c-d083a6465d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. レビューを日本語翻訳＆CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8dfe281-1067-4f03-95b6-7f8cc4a36196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Datetime用UDF\n",
    "@udf(returnType=StringType())\n",
    "def convert_yyyymmdd(date_str: str) -> str:\n",
    "    try:\n",
    "        if isinstance(date_str, str):\n",
    "            date_str = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', date_str)\n",
    "            return datetime.strptime(date_str, '%d %B %Y').strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# DateFlown用UDF\n",
    "@udf(returnType=StringType())\n",
    "def convert_yyyymm(date_str: str) -> str:\n",
    "    try:\n",
    "        if isinstance(date_str, str):\n",
    "            return datetime.strptime(date_str, '%B %Y').strftime('%Y-%m')\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "spark.udf.register(\"convert_yyyymmdd\", convert_yyyymmdd)\n",
    "spark.udf.register(\"convert_yyyymm\", convert_yyyymm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c74e6d7-af3a-4341-a639-5bbb83ff2ab7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "日本語翻訳"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "WITH prompts AS (\n",
    "  SELECT\n",
    "    No,\n",
    "    OverallRating,\n",
    "    -- ReviewHeader,\n",
    "    CONCAT(\n",
    "      \"<前提>あなたは、British Airwaysの顧客Feed Back専門のプロの翻訳アシスタントです。\",\n",
    "      \"\\n<指示>次のレビューヘッダーを自然な日本語に翻訳して下さい。レビューヘッダー:\\n\",\n",
    "      ReviewHeader,\n",
    "      \"\\n<注意>\",\n",
    "      \"\\n・「〜です」「〜ます」などの表現は避け、レビューヘッダーらしい言い切り表現を遵守してください。\"\n",
    "      \"\\n・翻訳結果のみ出力してください。補足は一切不要です。\"\n",
    "      ) AS ReviewHeader_prompt,\n",
    "    Name,\n",
    "    convert_yyyymmdd(Datetime) AS Datetime,           -- '16th November 2023' -> '2023-11-16'\n",
    "    VerifiedReview,\n",
    "    -- ReviewBody,\n",
    "    CONCAT(\n",
    "      \"<前提>あなたは、British Airwaysの顧客Feed Back専門のプロの翻訳アシスタントです。\",\n",
    "      \"\\n<指示>次のレビュー本文を自然で違和感のない日本語に翻訳して下さい。レビュー本文:\\n\",\n",
    "      ReviewBody,\n",
    "      \"\\n<注意>\",\n",
    "      \"\\n・翻訳結果のみ出力してください。補足は一切不要です。\"\n",
    "      ) AS ReviewBody_prompt,\n",
    "    TypeOfTraveller,\n",
    "    SeatType,\n",
    "    Route,\n",
    "    convert_yyyymm(DateFlown) AS DateFlown,        -- 'November 2023' -> '2023-11'\n",
    "    SeatComfort,\n",
    "    CabinStaffService,\n",
    "    GroundService,\n",
    "    ValueForMoney,\n",
    "    Recommended,\n",
    "    Aircraft,\n",
    "    FoodandBeverages,\n",
    "    InflightEntertainment,\n",
    "    WifiandConnectivity\n",
    "  FROM {MY_CATALOG}.{MY_SCHEMA}.bz_reviews_en\n",
    "  -- LIMIT 10\n",
    "),\n",
    "ja AS (\n",
    "  SELECT\n",
    "    No,\n",
    "    OverallRating,\n",
    "    ReviewHeader_prompt,\n",
    "    ai_query('databricks-claude-3-7-sonnet', ReviewHeader_prompt, failOnError => False).result AS ReviewHeader,\n",
    "    Name,\n",
    "    Datetime,\n",
    "    VerifiedReview,\n",
    "    ReviewBody_prompt,\n",
    "    ai_query('databricks-claude-3-7-sonnet', ReviewBody_prompt, failOnError => False).result AS ReviewBody,\n",
    "    TypeOfTraveller,\n",
    "    SeatType,\n",
    "    Route,\n",
    "    DateFlown,\n",
    "    SeatComfort,\n",
    "    CabinStaffService,\n",
    "    GroundService,\n",
    "    ValueForMoney,\n",
    "    Recommended,\n",
    "    Aircraft,\n",
    "    FoodandBeverages,\n",
    "    InflightEntertainment,\n",
    "    WifiandConnectivity\n",
    "  FROM prompts\n",
    ")\n",
    "SELECT\n",
    "  No,\n",
    "  OverallRating,\n",
    "  ReviewHeader_prompt,\n",
    "  -- ReviewHeader,\n",
    "  COALESCE(ReviewHeader, '-') AS ReviewHeader,\n",
    "  Name,\n",
    "  Datetime,\n",
    "  VerifiedReview,\n",
    "  ReviewBody_prompt,\n",
    "  ReviewBody,\n",
    "  COALESCE(ReviewBody, '-') AS ReviewBody,\n",
    "  TypeOfTraveller,\n",
    "  SeatType,\n",
    "  Route,\n",
    "  DateFlown,\n",
    "  SeatComfort,\n",
    "  CabinStaffService,\n",
    "  GroundService,\n",
    "  ValueForMoney,\n",
    "  Recommended,\n",
    "  Aircraft,\n",
    "  FoodandBeverages,\n",
    "  InflightEntertainment,\n",
    "  WifiandConnectivity\n",
    "FROM ja\n",
    "\"\"\")\n",
    "\n",
    "print(df.count())\n",
    "print(df.columns)\n",
    "# display(df)\n",
    "display(df.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48d914a5-7b46-4a56-ab48-5d580280b038",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CSV出力"
    }
   },
   "outputs": [],
   "source": [
    "selected_df = df.select(\n",
    "    \"No\",\n",
    "    \"OverallRating\",\n",
    "    \"ReviewHeader\",\n",
    "    \"Name\",\n",
    "    \"Datetime\",\n",
    "    \"VerifiedReview\",\n",
    "    \"ReviewBody\",\n",
    "    \"TypeOfTraveller\",\n",
    "    \"SeatType\",\n",
    "    \"Route\",\n",
    "    \"DateFlown\",\n",
    "    \"SeatComfort\",\n",
    "    \"CabinStaffService\",\n",
    "    \"GroundService\",\n",
    "    \"ValueForMoney\",\n",
    "    \"Recommended\",\n",
    "    \"Aircraft\",\n",
    "    \"FoodandBeverages\",\n",
    "    \"InflightEntertainment\",\n",
    "    \"WifiandConnectivity\"\n",
    ")\n",
    "\n",
    "# # write table\n",
    "# selected_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{MY_CATALOG}.{MY_SCHEMA}.bz_reviews_ja\")\n",
    "\n",
    "# export csv files\n",
    "selected_df.coalesce(1).toPandas().to_csv(f\"/Volumes/{MY_CATALOG}/{MY_SCHEMA}/{MY_VOLUME}/JA/BA_AirlineReviews_new.csv\", index=False, quoting=1)\n",
    "\n",
    "print(selected_df.count())\n",
    "print(selected_df.columns)\n",
    "display(selected_df.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94bc2b8e-06bb-48b2-b597-b7289465ec2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# spark.sql(f\"\"\"\n",
    "# SELECT\n",
    "#   MAX(OverallRating) as max_rate,\n",
    "#   MIN(OverallRating) as min_rate\n",
    "# FROM {MY_CATALOG}.{MY_SCHEMA}.bz_reviews_ja\n",
    "# \"\"\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1332008936166499,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02_EN_to_JP",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
